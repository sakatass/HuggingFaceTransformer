{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=messages = pd.read_csv('/content/Huggingfacetransformer/SMSSpamCollection', sep='\\t',\n",
        "                           names=[\"label\", \"message\"])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HpjeZkKHscPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=list(df['message'])"
      ],
      "metadata": {
        "id": "-QanVR34tGkp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=list(df['label'])"
      ],
      "metadata": {
        "id": "meBvH_HCtLKp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=list(pd.get_dummies(y,drop_first=True)['spam'])"
      ],
      "metadata": {
        "id": "rTTSrUIVtRu2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n"
      ],
      "metadata": {
        "id": "UtOomMUGtX9-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "g5yxvNBful8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "Km8qX1l2uoTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "YEptu09huqH3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    y_test\n",
        "))"
      ],
      "metadata": {
        "id": "2tofhioAu0z0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    eval_steps=100,\n",
        ")"
      ],
      "metadata": {
        "id": "by96eT5IwxaS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlgvmsRIw4zB",
        "outputId": "6d16d219-ad99-4410-e918-80872f0e6845"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/trainer_tf.py:118: FutureWarning: The class `TFTrainer` is deprecated and will be removed in version 5 of Transformers. We recommend using native Keras instead, by calling methods like `fit()` and `predict()` directly on the model object. Detailed examples of the Keras style can be found in our examples at https://github.com/huggingface/transformers/tree/main/examples/tensorflow\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjz1ualdyhBJ",
        "outputId": "8fa9beb9-a55b-4490-9110-c35162473752"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.022883769444056918}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkNBeMy5ijF",
        "outputId": "85622893-0e2f-43cb-fde1-98f933001b5d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 3.198942 , -3.2710042],\n",
              "       [-2.5848246,  2.5781653],\n",
              "       [ 2.9858174, -3.0430813],\n",
              "       ...,\n",
              "       [ 2.8699377, -2.8572302],\n",
              "       [-2.9087536,  2.914901 ],\n",
              "       [ 3.2207057, -3.273068 ]], dtype=float32), label_ids=array([0, 1, 0, ..., 0, 1, 0], dtype=int32), metrics={'eval_loss': 0.022886390345437185})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output=trainer.predict(test_dataset)[1]"
      ],
      "metadata": {
        "id": "kl11JMsI6G4j"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_test,output)\n",
        "cm\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "512cOFxe6ILl",
        "outputId": "eb029fc6-8a4e-466a-dabd-0b7d6fd125bb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[955,   0],\n",
              "       [  0, 160]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('senti_model')"
      ],
      "metadata": {
        "id": "ml125gwk6KF7"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}